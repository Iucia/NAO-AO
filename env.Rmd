---
title: "Enviromental characterization of North Atlantic and Arctic stations"
subtitle: "Ordination, Clustering and outliers detection"
author: "Lucia Campese"
date: "Jan-Feb 2021"
output:
  html_document:
    code_folding: hide
---

  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<style>
.column-left{
  float: left;
  width: 50%;
  text-align: left;
}
.column-right{
  float: right;
  width: 50%;
  text-align: right;
}
</style>
  
<br>

### Aim
The aim is to characterize the study site from an environmental point of view using ordination and clustering methods, thus providing an overview of relationships between objects and variables. This is a starting point for following analyses, since it allows to note trends, groupings, key variables, and potential outliers.

The results of this step will be 

+ **1.** interpreted in the light of what we expect in terms of salinity, temperature and nutrient gradients from current knowledge of oceanic currents;

+ **2.** compared to patterns in OTUs/genes.


<br>

### Dataset
##### Data: TARA Oceans and Tara Oceans Polar circle environmental data
##### Study site: Atlantic and Arctic Ocean stations, from station 143 to 196 [*]
[*] Note: We exclude stations from 201 to 210 because they are mainly influenced by outflowing currents from the Arctic Ocean.


### Study site (add currents)

<div class="column-left">
```{r warning=FALSE, message=FALSE, cache=FALSE, fig.align='center', fig.height=8, fig.width=8}
library(tidyverse)
data("wrld_simpl", package = "maptools")
x_lines <- seq(-120,180, by = 60)
env_data <- readxl::read_xlsx("C:/Users/Userszn/Documents/PhD/script/NAO_AO_transition/Environmental_Analysis/Environmental_parameters_atlantification.xlsx")

ggplot() +
  geom_polygon(data = wrld_simpl, aes(x = long, y = lat, group = group), fill = "grey", colour = "black", alpha = 0.8) +  # Convert to polar coordinates
  coord_map("ortho", orientation = c(90, 0, 0)) +
  scale_y_continuous(breaks = seq(25, 90, by = 5), labels = NULL) +  # Removes Axes and labels
  scale_x_continuous(breaks = NULL) +
  xlab("") +
  ylab("") +  # Adds labels
  geom_text(aes(x = 180, y = seq(25, 85, by = 10), hjust = -0.2, label = paste0(seq(25, 85, by = 10), "°N"))) +
  geom_text(aes(x = x_lines, y = 39, label = c("120°W", "60°W", "0°", "60°E", "120°E", "180°W"))) +  # Adds axes
  geom_hline(aes(yintercept = 25), size = 1)  +
  geom_segment(aes(y = 25, yend = 90, x = x_lines, xend = x_lines), linetype = "dashed") +  # Change theme to remove axes and ticks
  theme(panel.background = element_blank(),
        panel.grid.major = element_line(size = 0.25, linetype = 'dashed',
                                        colour = "black"),
        axis.ticks=element_blank()) +
  geom_point(aes(x=env_data$Longitude, y=env_data$Latitude), shape=19, fill="blue", color="blue", size=3) +
  ggrepel::geom_label_repel(aes(x=env_data$Longitude, y=env_data$Latitude, label = env_data$Station))

```
</div>
<div class="column-right">
![Dodd et al.,2012; red:inflow, violet:outflow; lightblue:rivers](C:/Users/Userszn/Documents/PhD/script/NAO_AO_transition/Environmental_Analysis/arctic_circulation.png)
</div>

<br>

<br>

### Workflow


<br>

#### **Choosing descriptors**

<br>

We want to choose descriptors important for characterizing the stations. Most of ordination techniques base on some assumptions (e.g. multinormality, linearity/unimodality); we therefore want to explore the descriptors chosen to see if they agree with assumptions.

<br>

Actual table of descriptors:


  Variable         |              Method
------------------ | --------------------------------------
Temperature        |       measured in situ 
Salinity           |       measured in situ
Oxygen             |       measured in situ
Nitrate            |     calculated from Darwin model
Nitrite            |     calculated from Darwin model
Ammonium           |     calculated from Darwin model
Iron               |     calculated from Darwin model
Sunshine duration  |  calculated from US Naval Observatory
Phosphate          |       measured in situ
Silicate           |       measured in situ



<br>

#### **Bivariate scatterplots**

<br>

First I visualize the relation between each pair of predictors, with bivariate scatter plots, correlation ellipses and confidence intervals below the diagonal, histograms and density plots on the diagonal, and the Spearman correlation above the diagonal, with astricks indicating the significance of correlations.
Outlier stations are highlighted in green and yellow. 

```{r warning=FALSE, message=FALSE, cache=FALSE, fig.align='center', fig.height=10, fig.width=12}
library(psych)

env_data_1 <- env_data %>% 
  rename(Temp = `T`,
         PO4 = Phos,
         SiOH4 = Si) %>% 
  mutate(Station = as.character(Station)) %>% 
  select(Station, Temp:SiOH4) %>% 
  as.data.frame()

rownames(env_data_1) <- env_data_1$Station

### handling outliers 
# The psych package contains a function 
#that quickly calculates and plots MDs:
D2 <- outlier(env_data_1[,-1], plot = FALSE)
#We see 5 outlier stations highlighted. However they do not seem so distant from the others, except for the station 194. Also, most of the points, fall below or after the
#line. The behaviour is strange, thus we might prefer a more formal test of outliers by using a cut-off score 
#for MD. Here, I'll recalcuate the MDs using the mahalanobis function and identify those that fall above the 
#cut-off score for a chi-square with k degrees of freedom (ncol in case I want to add or remove variables later):
md <- mahalanobis(env_data_1[,-1], center = colMeans(env_data_1[,-1]),
                  cov = cov(env_data_1[,-1]))

alpha <- 0.001
cutoff <- (qchisq(p = 1 - alpha, df = ncol(env_data_1[,-1])))
names_outliers_MH <- which(md > cutoff)
###col cutoff calcolato così, non escludo nessuna stazione. 
##guardiamo a occhio:
D2_values_df <- as.data.frame(D2) %>% 
  rownames_to_column("station")


#vedo a occhio che potrei applicare un cutoff > 18 per evidenziare la 196 (e plottarla in giallo)  e un cutoff > 21 per evidenziare la 194 (e plottarla in verde)
D2_env_df <- data.frame(env_data_1[,-1],D2)

mycol <- case_when(D2_env_df$D2 <=18 ~ "blue",
                   (D2_env_df$D2 > 18 & D2_env_df$D2 < 21) ~ "yellow",
                   TRUE ~ "green")

pairs.panels(D2_env_df[,-11], #remove the D2 column 
             bg = mycol,
             #bg=c("blue","yellow")[(D2 > 18)+1],
             pch=21,
             method = "spearman",
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE, # show correlation ellipses
             ci = TRUE,
             stars = TRUE,
             loess = TRUE)

```

##### Results:

+ Variables never follow a normal distribution. 

+ Some pairs of variables show a strong or moderate correlation, both negatively and positively:

<br>


Variable pair  | Correlation strenght  | Correlation sign   
-------------- | --------------------- | ----------------- 
Temp - Sal     | high                  | positive
Temp - O2      | high                  | negative
Temp - SSD     | high                  | negative
Sal - O2       | high                  | negative           
Sal - NO3      | high                  | negative
Sal - PO4      | high                  | negative
O2- SSD        | high                  | positive
Sal - NH4      | moderate              | positive
Sal - SSD      | moderate              | negative
O2 - NO3       | moderate              | positive 
O2 - PO4       | moderate              | positive
NO3 - NH4      | moderate              | negative
NO3 - SSD      | moderate              | positive
NO3 - PO4      | moderate              | positive
NO2 - NH4      | moderate              | positive
NO2 - SSD      | moderate              | negative
NH4 - Fe       | moderate              | negative
PO4 - SiOH4    | moderate              | positive

<br>

+ Should we remove highly correlated variables? 

<br>


<br>

#### **Handling outliers**

<br>


From a visual inspection, it seems that two stations are clear outliers for Salinity (green dot) and NO2 (yellow dot), respectively, but they do not behave as outliers for most of the other variables.

In order to identify and deal with outliers in a more rigorous manner, I apply the **Mahalanobis Distance** (MD), that calculates the distance of each case from the central mean. Larger values indicate that a case is farther from where most of the points cluster.


Have a look at the distribution of Mahalanobis Distance per each station:
```{r, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}
library(ggpubr)
ggdensity(D2_values_df, 
          x = "D2", y = "..count..",
          #xlab = "Number of citation",
          #ylab = "Number of genes",
          #fill = "lightgray", color = "black",
          label = "station", repel = TRUE,
          main = "Density plot of D2")
# font.label = list(color= "citation_index"))#,
#font.label = list(color= "citation_index"),
#xticks.by = 20, # Break x ticks by 20
#gradient.cols = c("blue", "red"),
#legend = c(0.7, 0.6),                                 
#legend.title = ""       # Hide legend title
#)
```

##### Results:

The graph shows the value of Mahalanobis distance (D2) per each station:
+ Station 194 is an actual outlier, showing the highest D2. 
+ Station 196, however, despite being a clear outlier for nitrite (as seen from bivariate scatterplots), does not depart from the general trend. 
+ Moreover, we can roughly identify two groups of stations: a group with D2 < 10 and one with D2 > 10.

Note: this *does not* mean that stations of the same "group" are similar to eah other. To look at how stations group together according to Mahalanobis distance, we have to calculate it *pariwise*, and apply a cluster analysis. 

<br>

<br>

#### **Cluster Analysis**

```{r warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}
#calcoliamo malahnobis pairwise e facicamo dendrogramma
nrmy <- scale(env_data_1[,-1])
maha <- vegan::vegdist(nrmy, method = "mahalanobis")
maha.clust <- hclust(maha, method = "ward.D2")
dend <- as.dendrogram(maha.clust)
plot(dend)

```

##### Results:

The dendrogram shows 3 main clusters:

+ 1. One cluster containing a group with the two outliers and a group with 3 stations geographically belonging to the transition zone from Atlantic to Arctic Ocean;

+ 2. One Atlantic cluster with the exception of a sub-group with station 145 and the arctic station 175 (at the border between EEB and WEB);

+ 3. An Arctic cluster composed by a group of "atlantified" Arctic stations and another with stations more influenced by Pacific inflow (exception: station 180 - Kara Sea? -)

<br>

Cluster analyses show groups forming based on a distance matrix, Mahalanobis in this case. But what if we apply an ordination technique to the raw data?

Let's do a Principal Component Analysis, highlighting stations using the information provided by the clustering analysis.

<br>


#### **Principal Component Analysis**

### PCA {.tabset}

#### Biplot

```{r a1, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center', fig.width=10, fig.height=8}

library(vegan)

pca_env <- rda(env_data_1[,-1],
               scale=TRUE) #scale=T bases the PCA on the correlation matrix

library(ade4)
library(factoextra)
library(FactoMineR)
#dudi. #dudi.pca con scannf=F e nf=2
#(dudi.pca e'  la funzione di ade4 per calcolare una PCA, stabilisci a mano che vuoi solo due componenti)
pca_env_dudi <- dudi.pca(env_data_1[,-1], scannf=F, nf=2)


biplot(pca_env, #A biplot is plot which aims to represent both the observations and variables of a matrix of multivariate data on the same plot.
       choices = c(1, 2),
       scaling = 2, #Correlation biplot, scaling 2
       display = c("sites", "species"), 
       col = c(1,2),
       correlation = FALSE)

#How to interpret it:
#(1) Distances among objects in the biplot are approximations of
#their Mahalanobis distances in multidimensional space; they are not approximations of
#their Euclidean distances.
#(2) Projecting an object at right angle on a descriptor approximates the position of the object along that descriptor.
#(3) The length of the projection of a descriptor in reduced space is an approximation of its standard deviation. 
#(4) The angles between descriptors in the biplot reflect their correlations.(se p=q. in ogni caso
#le loro direzioni indicano se la correlazione è positiva o negativa)

```


#### Biplot highlighting mahalanobis clusters
```{r a2, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}
gr <- cutree(maha.clust, k=3)
grl <- levels(factor(gr))

fviz_pca_biplot(pca_env_dudi, 
                #label="var",
                col.ind = as.factor(gr), 
                #palette = c("blue", "green", "yellow", "green"),
                legend.title = "Cluster") +
                #habillage=as.factor(gr)) +
  #labs(color=NULL) + 
  ggtitle("") +
  theme(text = element_text(size = 15), 
        panel.background = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"),
        legend.position="none")
```

##### Results:

The PCA biplot (i.e. plot of both objects and predictors) shows that the clustering and ordination agree with the grouping of the majority of stations. The PCA seems also to better agree with geographic distribution of stations.

#### Correlation circle

```{r a3, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}

s.corcircle(pca_env_dudi$co) #performs the scatter diagram of a correlation circle.
```

###

##### Diagnostics:

### {.tabset}

#### Screeplot
```{r warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}

#Quanta varianza stiamo spiegando con i due assi?
fviz_screeplot(pca_env_dudi, addlabels = T, ylim = c(0, 50))
pca_env_summary <- summary(pca_env)#$CA[[1]])

#pca_env_summary$cont
```

+ the first two PCs explain the 66% of the variance.


#### Stressplot
```{r warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}

stressplot(pca_env)
#The goodness of fit for data reduction techniques can be easily assessed with Shepard diagrams. 
#A Shepard diagram compares how far apart your data points are before and after you transform them 
#(ie: goodness-of-fit) as a scatter plot.

```

+ The stressplot shows if the distances among objects are well preserved in the reduced space. In the graph all point lie in the inferior triangle, showing that the distance between projected data is always lower than the input matrix distance. This means that with the PCA we are constantly underestimating the distances between points and the projection has the bias of showing as close things that are actually more distant.

###

### {.tabset}

<br>

Let's see how far from linearity the different variables are

#### PC1
<div class="column-left">
```{r b1a, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}

#estraiamo i loadings: loading = weight == eigenvector
loadings <- scores (pca_env, display = 'species', scaling = 0)

score(pca_env_dudi, 1)
```
</div>
<div class="column-right">
```{r b1b, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}

#sort (abs (loadings[,1]), decreasing = TRUE)
# Contributions of variables to PC1
fviz_contrib(pca_env_dudi, choice = "var", axes = 1, top = 10)
```
</div>

#### PC2 
<div class="column-left">
```{r b2a, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}
score(pca_env_dudi, 2)
```
</div>
<div class="column-right">
```{r b2b, warning=FALSE, message=FALSE, cache=FALSE, fig.align='center'}
#sort (abs (loadings[,2]), decreasing = TRUE)
# Contributions of variables to PC2
fviz_contrib(pca_env_dudi, choice = "var", axes = 2, top = 10)

#(stiamo cercando di guardare quanto lontane dalla linearita' sono le diverse variabili)

#X = dato scalato: row score == PC1 score: la coordinata di quella stazione sull’asse PC1
#Y = dato non scalato
#Ferro ed NO2 non vanno molto bene
#Confronta questo grafico con l’output di sort() blabla di ieri, che ti ordina le variabili per 
#importanza per la PC1 e PC2. 
#A un certo punto O2 smette di diventare informativo. (questo si vede dal grafico).
```
</div>

### 

<br>

<br> 

<br> 

### **Conclusion**

The projection of the data with PCA tells us that there is a structure among stations. There are groups of station that we can characterize. One of the main aims of the PCA is to reduce the number of variables considered in the analysis: we did it, because with the first two principal components explain around the 66% of the total variance.







